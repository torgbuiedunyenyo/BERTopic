{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard library imports\n",
    "from collections import Counter\n",
    "import copy\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "import glob\n",
    "from os import access, R_OK\n",
    "import re\n",
    "from operator import attrgetter\n",
    "import csv\n",
    "\n",
    "#third party imports\n",
    "from bertopic import BERTopic\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.base\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "import joblib\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE_NUMBER = 1\n",
    "PHASE_TITLE = 'congress'\n",
    "\n",
    "def write_csv(df, csv_path: str):\n",
    "  if not csv_path.endswith(\".csv\"):\n",
    "    raise ValueError(\"Please provide valid csv name for topic csv\")\n",
    "    df.to_csv(csv_path, index=None)\n",
    "\n",
    "def given_a_topic_list_original_statements(dataframe ,topic_number: int, cluster_column_name: str = None):\n",
    "    if cluster_column_name is None:\n",
    "        return dataframe[dataframe['clusters'] == topic_number]\n",
    "    return dataframe[dataframe[cluster_column_name] == topic_number]\n",
    "\n",
    "def get_docs_from_df(dataframe, columns: list=None):\n",
    "  \n",
    "  if columns is None:\n",
    "    columns = [\"combined_responses\"]\n",
    "\n",
    "  docs = []\n",
    "  for column in columns:\n",
    "    column_to_list = dataframe[column].tolist()\n",
    "    column_to_list = [doc.lower().strip() for doc in column_to_list]\n",
    "    # columns_to_list = [doc for doc in column_to_list if doc != '']\n",
    "    docs.extend(column_to_list)\n",
    "  \n",
    "  return docs\n",
    "\n",
    "def get_text_for_cluster(list_of_sentences):\n",
    "    text = \"\"\n",
    "    for sentence in list_of_sentences:\n",
    "        text = text + \" \" + sentence\n",
    "\n",
    "    return text\n",
    "\n",
    "def given_cluster_filter_dataset(df, cluster_id: int):\n",
    "    return df[df['clusters'] == cluster_id]\n",
    "\n",
    "def _get_model_path_2(folder_path: str, file_name:str):\n",
    "    return os.path.join(folder_path, \"{}_Phase{}_{}.zip\".format(file_name, PHASE_NUMBER, PHASE_TITLE))\n",
    "\n",
    "def _get_csv_path(folder_path: str, file_name:str):\n",
    "    return os.path.join(folder_path, \"{}.csv\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This path should be to a folder that will hold all of your models and csvs\n",
    "PHASE_DIR = Path(\"/content/drive/MyDrive/tradoc/Phase_{}\".format(PHASE_NUMBER))\n",
    "assert PHASE_DIR.is_dir()\n",
    "#this path appends a folder inside of your PHASE_DIR for  inputs and outputs.\n",
    "PHASE_DATASET_DIR = Path(\"/content/drive/MyDrive/tradoc/Phase_{}/Datasets\".format(PHASE_NUMBER))\n",
    "assert PHASE_DATASET_DIR.exists()\n",
    "#This path appends a folder inside of your PHASE_DIR for saving and loading model files.\n",
    "MODEL_SAVE_PATH = Path('/content/drive/MyDrive/tradoc/Phase_{}/Models/{}'.format(PHASE_NUMBER, PHASE_TITLE))\n",
    "MODEL_LOAD_PATH = Path('/content/drive/MyDrive/tradoc/Phase_{}/Models/{}'.format(PHASE_NUMBER, PHASE_TITLE))\n",
    "\n",
    "assert MODEL_SAVE_PATH.is_dir()\n",
    "assert MODEL_LOAD_PATH.is_dir()\n",
    "#This path is for a separate folder in your PHASE_DIR for \n",
    "TOPIC_SAVE_PATH = Path('/content/drive/MyDrive/tradoc/Phase_{}/Datasets'.format(PHASE_NUMBER))\n",
    "TOPIC_LOAD_PATH = Path('/content/drive/MyDrive/tradoc/Phase_{}/Datasets/'.format(PHASE_NUMBER))\n",
    "assert MODEL_SAVE_PATH.is_dir()\n",
    "assert MODEL_LOAD_PATH.is_dir()\n",
    "\n",
    "#DO NOT SET THIS TO FALSE\n",
    "COMPUTE_PROBABILITIES=True\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This csv leads to data from InsightAI. If you are pulling from DB, you can parse with this notebook: https://drive.google.com/file/d/1nguZ3vEBPzrMvvrDkYVRGxeXSakT33LM/view?usp=sharing\n",
    "PHASE_DATA_PATH = '/content/drive/MyDrive/tradoc/Phase_7/Datasets/tradoc-78-detailed-data-from-Sanjay-with-company.csv'\n",
    "\n",
    "\n",
    "#this path is for the file that will be saved with the original statements and their associated topics\n",
    "PHASE_DATA_WITH_CLUSTERS_PATH = str(PHASE_DATASET_DIR)  + \"/\" +'phase_{}_data_with_clusters_blockers.csv'.format(PHASE_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loading the parsed data as a DataFrame\n",
    "phase_df = pd.read_csv(PHASE_DATA_PATH, na_filter=False)\n",
    "phase_df.replace(np.nan, \"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple separate columns to perform a single set of modeling\n",
    "# For example, if we want to model `problems` and `background`, enter them as a list and both columns will be concatenated together for modeling.\n",
    "list_of_columns_to_model_individually = ['basic_need']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We combine the problems and background columns because they are 2 parts of the same question\n",
    "phase_df['combined_responses'] = phase_df[list_of_columns_to_model_individually].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the combined columns only\n",
    "X = phase_df['combined_responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(nr_topics='auto', n_gram_range=(1,5), calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_models_and_topics(\n",
    "    data_df: pd.DataFrame,\n",
    "    model_save_path: str,\n",
    "    topic_save_path: str,\n",
    "    col_name: str = \"speech\",\n",
    "    calculate_probabilities: bool = True\n",
    "):\n",
    "  if col_name not in data_df.columns:\n",
    "     raise ValueError(\"Please give a valid column name and/or dataframe\")\n",
    "\n",
    "  model_names = [\n",
    "    f\"topic_model_for{congress_num}_speeches_orig_spell\"\n",
    "    for congress_num in range(43, 112)            \n",
    "  ]\n",
    "\n",
    "  for model_name in model_names:\n",
    "\n",
    "    try:\n",
    "      bt_model = BERTopic(nr_topics='auto', n_gram_range=(1,5), calculate_probabilities=True)\n",
    "      bt_model.fit(X)\n",
    "      topics, probabilities = bt_model.transform(X)\n",
    "\n",
    "      model_full_name = str(model_name) + \"_Phase{}_{}.zip\".format(PHASE_NUMBER, PHASE_TITLE)\n",
    "      bt_model.save(model_full_name)\n",
    "      print('something got saved in content!')\n",
    "      print(model_full_name)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_save_models_and_topics(data_df=phase_df, model_save_path=MODEL_SAVE_PATH, topic_save_path=TOPIC_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3341e6fbbb2a942d35613e0398491de77be0cce801c357fa5335ad1ceae197b0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('bertopic-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
